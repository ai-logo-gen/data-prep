{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9009cf36",
   "metadata": {},
   "source": [
    "# Amazing Logos V4 - Step 1: Data Processing\n",
    "\n",
    "This notebook processes the amazing_logos_v4 dataset from the input folder:\n",
    "- Reads the dataset from input/amazing_logos_v4/\n",
    "- Assigns unique IDs with \"amazing_logo_v4\" prefix\n",
    "- Saves logos as 256x256 images in output/amazing_logos_v4/images/256x256/\n",
    "- Saves metadata (ID + prompt) in output/amazing_logos_v4/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1abbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path: ..\\input\\amazing_logos_v4\n",
      "Output images: ..\\output\\amazing_logos_v4\\images\\256x256\n",
      "Output data: ..\\output\\amazing_logos_v4\\data\n",
      "Input path exists. Contents:\n",
      "  - dataset_dict.json\n",
      "  - train\n"
     ]
    }
   ],
   "source": [
    "# Setup paths\n",
    "input_dataset = Path('../../input/amazing_logos_v4')\n",
    "output_base = Path('../../output/amazing_logos_v4')\n",
    "output_images = output_base / 'images' / '256x256'\n",
    "output_data = output_base / 'data' / 'amazing_logos_v4_cleanup'\n",
    "\n",
    "# Create output directories\n",
    "output_images.mkdir(parents=True, exist_ok=True)\n",
    "output_data.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Input dataset: {input_dataset}\")\n",
    "print(f\"Output images: {output_images}\")\n",
    "print(f\"Output data: {output_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73616320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amazing_logos_v4 dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340736fb445b4fd1a6901e965bd00598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset info: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'text'],\n",
      "        num_rows: 397251\n",
      "    })\n",
      "})\n",
      "Using train split with 397251 entries\n",
      "\n",
      "Dataset columns: ['image', 'text']\n",
      "\n",
      "First example keys: dict_keys(['image', 'text'])\n",
      "  image: PIL Image ((512, 512))\n",
      "  text: Simple elegant logo for Mandarin Oriental, Fan Hong kong Lines Paper, Hospitality, successful vibe, ...\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "print(\"Loading amazing_logos_v4 dataset...\")\n",
    "data = None\n",
    "try:\n",
    "    # Try loading as HuggingFace dataset\n",
    "    dataset = load_from_disk(str(input_path))\n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "    print(f\"Dataset info: {dataset}\")\n",
    "    \n",
    "    # Get the train split (assuming it's the main data)\n",
    "    if 'train' in dataset:\n",
    "        data = dataset['train']\n",
    "        print(f\"Using train split with {len(data)} entries\")\n",
    "    else:\n",
    "        data = dataset\n",
    "        print(f\"Using dataset directly with {len(data)} entries\")\n",
    "    \n",
    "    # Show dataset structure\n",
    "    print(f\"\\nDataset columns: {data.column_names}\")\n",
    "    \n",
    "    # Show first example\n",
    "    if len(data) > 0:\n",
    "        first_example = data[0]\n",
    "        print(f\"\\nFirst example keys: {first_example.keys()}\")\n",
    "        for key, value in first_example.items():\n",
    "            if key == 'image':\n",
    "                print(f\"  {key}: PIL Image ({value.size})\")\n",
    "            elif isinstance(value, str) and len(value) > 100:\n",
    "                print(f\"  {key}: {value[:100]}...\")\n",
    "            else:\n",
    "                print(f\"  {key}: {value}\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Trying alternative loading methods...\")\n",
    "    data = None\n",
    "\n",
    "# Check if data was loaded successfully\n",
    "if data is None:\n",
    "    print(\"❌ Failed to load dataset. Please check the input path and dataset format.\")\n",
    "    raise RuntimeError(\"Dataset loading failed\")\n",
    "else:\n",
    "    print(f\"✅ Dataset loaded successfully with {len(data)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae315900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataFrame with id and text columns...\n",
      "Extracting text data from dataset...\n",
      "Extracted 397251 text entries\n",
      "Creating ID-text pairs...\n",
      "Extracted 397251 text entries\n",
      "Creating ID-text pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating metadata: 397252it [00:00, 1076474.78it/s]                            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PROCESSING COMPLETE ===\n",
      "Created DataFrame with 397251 rows\n",
      "Columns: ['id', 'text']\n",
      "Metadata CSV saved to: ..\\output\\amazing_logos_v4\\data\\amazing_logos_v4_metadata.csv\n",
      "\n",
      "=== SAMPLE DATA ===\n",
      "                      id                                               text\n",
      "0  amazing_logo_v4000000  Simple elegant logo for Mandarin Oriental, Fan...\n",
      "1  amazing_logo_v4000001  Simple elegant logo for Alfa, Hexagon Poland T...\n",
      "2  amazing_logo_v4000002  Simple elegant logo for Kuraray, G Japan K Out...\n",
      "3  amazing_logo_v4000003  Simple elegant logo for Valwood Park, Lines Ro...\n",
      "4  amazing_logo_v4000004  Simple elegant logo for Cinepaq, C Circle Film...\n",
      "5  amazing_logo_v4000005  Simple elegant logo for Baumechanik Barleben, ...\n",
      "6  amazing_logo_v4000006  Simple elegant logo for Werbeagentur Zühlke, ...\n",
      "7  amazing_logo_v4000007  Simple elegant logo for Josef Grabner, Circles...\n",
      "8  amazing_logo_v4000008  Simple elegant logo for Danefae, Beard Denmark...\n",
      "9  amazing_logo_v4000009  Simple elegant logo for IPCT, Bicycle chain Ci...\n",
      "Metadata CSV saved to: ..\\output\\amazing_logos_v4\\data\\amazing_logos_v4_metadata.csv\n",
      "\n",
      "=== SAMPLE DATA ===\n",
      "                      id                                               text\n",
      "0  amazing_logo_v4000000  Simple elegant logo for Mandarin Oriental, Fan...\n",
      "1  amazing_logo_v4000001  Simple elegant logo for Alfa, Hexagon Poland T...\n",
      "2  amazing_logo_v4000002  Simple elegant logo for Kuraray, G Japan K Out...\n",
      "3  amazing_logo_v4000003  Simple elegant logo for Valwood Park, Lines Ro...\n",
      "4  amazing_logo_v4000004  Simple elegant logo for Cinepaq, C Circle Film...\n",
      "5  amazing_logo_v4000005  Simple elegant logo for Baumechanik Barleben, ...\n",
      "6  amazing_logo_v4000006  Simple elegant logo for Werbeagentur Zühlke, ...\n",
      "7  amazing_logo_v4000007  Simple elegant logo for Josef Grabner, Circles...\n",
      "8  amazing_logo_v4000008  Simple elegant logo for Danefae, Beard Denmark...\n",
      "9  amazing_logo_v4000009  Simple elegant logo for IPCT, Bicycle chain Ci...\n"
     ]
    }
   ],
   "source": [
    "# Save metadata to CSV\n",
    "csv_path = output_data / 'metadata.csv'\n",
    "df_metadata.to_csv(csv_path, index=False)\n",
    "print(f\"Metadata CSV saved to: {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
