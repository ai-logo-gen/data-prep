{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logo Data Processor\n",
    "\n",
    "This notebook downloads the logo dataset in parquet format, processes the data to add unique IDs, and saves the logo metadata and images in specified formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image decoding function defined\n"
     ]
    }
   ],
   "source": [
    "def decode_image_data(image_data):\n",
    "    \"\"\"Decode image data to PIL Image - handles multiple formats\"\"\"\n",
    "    try:\n",
    "        # Case 1: Image data is a dictionary (HuggingFace datasets format)\n",
    "        if isinstance(image_data, dict):\n",
    "            if 'bytes' in image_data:\n",
    "                # Direct bytes data\n",
    "                image_bytes = image_data['bytes']\n",
    "                if isinstance(image_bytes, bytes):\n",
    "                    image = Image.open(BytesIO(image_bytes))\n",
    "                    return image\n",
    "                elif isinstance(image_bytes, str):\n",
    "                    # Base64 encoded bytes\n",
    "                    image_bytes = base64.b64decode(image_bytes)\n",
    "                    image = Image.open(BytesIO(image_bytes))\n",
    "                    return image\n",
    "            elif 'path' in image_data:\n",
    "                # Path to image file\n",
    "                image_path = image_data['path']\n",
    "                image = Image.open(image_path)\n",
    "                return image\n",
    "            else:\n",
    "                print(f\"Unknown dict format: {list(image_data.keys())}\")\n",
    "                return None\n",
    "        \n",
    "        # Case 2: Image data is a base64 string\n",
    "        elif isinstance(image_data, str):\n",
    "            # Remove data URL prefix if present\n",
    "            if image_data.startswith('data:image'):\n",
    "                image_data = image_data.split(',')[1]\n",
    "            \n",
    "            # Decode base64\n",
    "            image_bytes = base64.b64decode(image_data)\n",
    "            image = Image.open(BytesIO(image_bytes))\n",
    "            return image\n",
    "        \n",
    "        # Case 3: Image data is already bytes\n",
    "        elif isinstance(image_data, bytes):\n",
    "            image = Image.open(BytesIO(image_data))\n",
    "            return image\n",
    "        \n",
    "        else:\n",
    "            print(f\"Unknown image data type: {type(image_data)}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding image: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Image decoding function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directories\n",
    "output_dir = Path('../output')\n",
    "data_dir = output_dir / 'data'\n",
    "images_dir = output_dir / 'images'\n",
    "sizes = [256, 512, 1024]\n",
    "\n",
    "for size in sizes:\n",
    "    (images_dir / f'{size}x{size}').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the parquet data\n",
    "url = 'https://huggingface.co/datasets/logo-wizard/modern-logo-dataset/resolve/main/data/train-00000-of-00001-b64601da56687a05.parquet'\n",
    "response = requests.get(url)\n",
    "with open('logo_dataset.parquet', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_parquet('logo_dataset.parquet')\n",
    "\n",
    "# Add unique ID with prefix 'logowiz'\n",
    "df['unique_id'] = ['logowiz' + str(i).zfill(6) for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved logo metadata to ..\\output\\data\\logowiz_logo_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# Save logo metadata as CSV\n",
    "metadata_file = data_dir / 'logowiz_logo_metadata.csv'\n",
    "df.drop(columns='image').to_csv(metadata_file, index=False)\n",
    "print(f'Saved logo metadata to {metadata_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved logo bytes to ..\\output\\data\\logowiz_logo_bytes.csv\n"
     ]
    }
   ],
   "source": [
    "# Save logo bytes as CSV\n",
    "metadata_file = data_dir / 'logowiz_logo_bytes.csv'\n",
    "df.drop(columns='text').to_csv(metadata_file, index=False)\n",
    "print(f'Saved logo bytes to {metadata_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved logo metadata to ..\\output\\data\\logowiz_logo_metadata.csv\n",
      "Image processing completed.\n",
      "Image processing completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to save images in different sizes\n",
    "def save_image(image_data, unique_id):\n",
    "    try:\n",
    "        image = decode_image_data(image_data)\n",
    "        if image:\n",
    "            # Convert RGBA to RGB if necessary\n",
    "            if image.mode in ('RGBA', 'LA', 'P'):\n",
    "                # Create a white background\n",
    "                background = Image.new('RGB', image.size, (255, 255, 255))\n",
    "                if image.mode == 'P':\n",
    "                    image = image.convert('RGBA')\n",
    "                background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)\n",
    "                image = background\n",
    "            elif image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            for size in sizes:\n",
    "                img_resized = image.resize((size, size), Image.LANCZOS)\n",
    "                img_resized.save(images_dir / f'{size}x{size}' / f'{unique_id}.jpg')\n",
    "    except Exception as e:\n",
    "        print(f'Error processing image for {unique_id}: {e}')\n",
    "\n",
    "# Process and save images\n",
    "for idx, row in df.iterrows():\n",
    "    image_data = row['image']  # Assuming 'image' is the column name\n",
    "    unique_id = row['unique_id']\n",
    "    save_image(image_data, unique_id)\n",
    "\n",
    "print('Image processing completed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
